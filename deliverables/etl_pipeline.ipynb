{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from word2number import w2n\n",
    "\n",
    "DB_URI = \"\" #Fill in the DB URI\n",
    "engine = create_engine(DB_URI)\n",
    "\n",
    "\n",
    "# CLEANING UTILS\n",
    "\n",
    "def convert_to_number(val):\n",
    "    try:\n",
    "        return int(val)\n",
    "    except (ValueError, TypeError):\n",
    "        try:\n",
    "            return w2n.word_to_num(str(val).lower())\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def clean_numeric_column(series):\n",
    "    return series.apply(lambda x: convert_to_number(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "# EXTRACT + TRANSFORM\n",
    "def load_customers(path):\n",
    "    df = pd.read_json(path)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    return df\n",
    "\n",
    "def load_products(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    return df\n",
    "\n",
    "def load_inventory(path):\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = df.columns.str.lower()\n",
    "    for col in ['stock_level', 'reorder_level', 'avg_daily_sales', 'days_until_reorder']:\n",
    "        df[col] = clean_numeric_column(df[col])\n",
    "    return df\n",
    "\n",
    "def load_sales_folder(folder_path, limit=None):\n",
    "    all_files = sorted([\n",
    "        os.path.join(folder_path, f) \n",
    "        for f in os.listdir(folder_path) \n",
    "        if f.endswith('.xlsx')\n",
    "    ])\n",
    "    if limit:\n",
    "        all_files = all_files[:limit]\n",
    "    \n",
    "    sales_data = []\n",
    "    for file in all_files:\n",
    "        df = pd.read_excel(file)\n",
    "        df.columns = df.columns.str.lower()\n",
    "        df['sale_date'] = pd.to_datetime(df['sale_date'], errors='coerce')\n",
    "        df['quantity'] = clean_numeric_column(df['quantity'])\n",
    "        df['product_price'] = pd.to_numeric(df['product_price'], errors='coerce')\n",
    "        df['total_sale_amount'] = df['quantity'] * df['product_price']\n",
    "        sales_data.append(df)\n",
    "    \n",
    "    return pd.concat(sales_data, ignore_index=True)\n",
    "\n",
    "def transform_and_join(sales, customers, products, inventory):\n",
    "    # Join sales with customers and products\n",
    "    sales = sales.merge(customers, on='customer_id', how='left')\n",
    "    sales = sales.merge(products, on='product_id', how='left')\n",
    "    \n",
    "    # Optional: Join with inventory (not always 1:1, may need warehouse/date match logic)\n",
    "    sales = sales.merge(inventory, on='product_id', how='left')\n",
    "    \n",
    "    return sales\n",
    "\n",
    "\n",
    "# LOAD INTO DATABASE\n",
    "def load_to_sql(df, table_name, engine, if_exists='append'):\n",
    "    df.to_sql(table_name, con=engine, index=False, if_exists=if_exists, method='multi')\n",
    "    print(f\"Loaded {len(df)} records into '{table_name}'.\")\n",
    "\n",
    "\n",
    "# MAIN ETL FUNCTION\n",
    "\n",
    "\n",
    "def run_etl_pipeline(\n",
    "    sales_folder=\"sales/\",\n",
    "    customers_path=\"customers.json\",\n",
    "    products_path=\"products.csv\",\n",
    "    inventory_path=\"inventory.csv\",\n",
    "    output_path=\"output/cleaned_sales_data.csv\",\n",
    "    limit_sales_files=None\n",
    "):\n",
    "    print(\"Loading raw data...\")\n",
    "    customers = load_customers(customers_path)\n",
    "    products = load_products(products_path)\n",
    "    inventory = load_inventory(inventory_path)\n",
    "    sales = load_sales_folder(sales_folder, limit=limit_sales_files)\n",
    "\n",
    "    print(\"Cleaning and transforming...\")\n",
    "\n",
    "    # print(\"Transforming and joining...\")\n",
    "    # final_df = transform_and_join(sales, customers, products, inventory)\n",
    "\n",
    "    # print(f\"Saving output to {output_path}\")\n",
    "    # os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    # final_df.to_csv(output_path, index=False)\n",
    "    # print(\"ETL complete!\")\n",
    "\n",
    "    print(\"Loading to SQL database...\")\n",
    "    load_to_sql(customers, \"customers\", engine)\n",
    "    load_to_sql(products, \"products\", engine)\n",
    "    load_to_sql(inventory, \"inventory\", engine)\n",
    "    load_to_sql(sales, \"sales\", engine)\n",
    "\n",
    "    print(\" ETL Pipeline Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
